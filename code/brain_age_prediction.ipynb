{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-27 16:08:41.604604: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "import csv\n",
    "import nipy\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from dateutil import relativedelta\n",
    "\n",
    "from scipy import ndimage as nd\n",
    "import scipy.stats as stats\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "# -------------------  start importing keras module ---------------------\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Masking# Dropout\n",
    "from tensorflow.keras.layers import Conv3D, MaxPooling3D\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.utils import CustomObjectScope\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR = '/trinity/home/jyu/DeepVoxels/data/images/'\n",
    "MASK_DIR = '/trinity/home/jyu/DeepVoxels/data/standards/'\n",
    "WANG_DIR = '/trinity/home/jyu/DeepSurvival/Notebooks/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class imgZeropad:\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, img, use_padding=False):\n",
    "        self.set_crop(img, use_padding)\n",
    "    \n",
    "    #set crop locations\n",
    "    def set_crop(self, img, use_padding=False):\n",
    "        # argwhere will give you the coordinates of every non-zero point\n",
    "        true_data = np.argwhere(img)\n",
    "        # take the smallest points and use them as the top left of your crop\n",
    "        top_left = true_data.min(axis=0)\n",
    "        # take the largest points and use them as the bottom right of your crop\n",
    "        bottom_right = true_data.max(axis=0)\n",
    "        crop_indeces = [top_left, bottom_right+1]  # plus 1 because slice isn't inclusive\n",
    "\n",
    "        print('crop set to x[{}:{}], y[{}:{}], z[{}:{}]'.format(crop_indeces[0][0], crop_indeces[1][0], \n",
    "                                                                crop_indeces[0][1], crop_indeces[1][1], \n",
    "                                                                crop_indeces[0][2], crop_indeces[1][2]))\n",
    "\n",
    "        if use_padding == True:\n",
    "            shape = crop_indeces[1]-crop_indeces[0]\n",
    "            bottom_net = shape.astype(float)/2/2**3\n",
    "            top_net = np.ceil(bottom_net)*2*2**3\n",
    "            padding = (top_net-shape)/2\n",
    "            print('applying [{},{},{}] padding to image..'.format(padding[0], padding[1], padding[2]))\n",
    "            padding_l = padding.astype(int)\n",
    "            padding_r = np.ceil(padding).astype(int)\n",
    "            crop_indeces[0] -= padding_l\n",
    "            crop_indeces[1] += padding_r\n",
    "\n",
    "            print('crop set to x[{}:{}], y[{}:{}], z[{}:{}]'.format(crop_indeces[0][0], crop_indeces[1][0], \n",
    "                                                                    crop_indeces[0][1], crop_indeces[1][1], \n",
    "                                                                    crop_indeces[0][2], crop_indeces[1][2]))\n",
    "        else:\n",
    "            padding = np.zeros(3)\n",
    "        self.crop_indeces = crop_indeces\n",
    "        self.padding = padding\n",
    "        \n",
    "        shape = crop_indeces[1]-crop_indeces[0]\n",
    "        self.img_size = (shape[0], shape[1], shape[2])\n",
    "\n",
    "    #crop according to crop_indeces\n",
    "    def zerocrop_img(self, img, augment=False):\n",
    "        if augment:\n",
    "            randx = np.random.rand(3)*2-1\n",
    "            new_crop = self.crop_indeces+(self.padding*randx).astype(int)\n",
    "\n",
    "            cropped_img = img[new_crop[0][0]:new_crop[1][0],  \n",
    "                              new_crop[0][1]:new_crop[1][1],\n",
    "                              new_crop[0][2]:new_crop[1][2]]\n",
    "\n",
    "            flip_axis = np.random.rand(3)\n",
    "            if round(flip_axis[0]):\n",
    "                cropped_img = cropped_img[::-1,:,:]\n",
    "            if round(flip_axis[1]):\n",
    "                cropped_img = cropped_img[:,::-1,:]\n",
    "            if round(flip_axis[2]):\n",
    "                cropped_img = cropped_img[:,:,::-1]\n",
    "                \n",
    "        else:\n",
    "            cropped_img = img[self.crop_indeces[0][0]:self.crop_indeces[1][0],  \n",
    "                              self.crop_indeces[0][1]:self.crop_indeces[1][1],\n",
    "                              self.crop_indeces[0][2]:self.crop_indeces[1][2]]\n",
    "            \n",
    "        return cropped_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_data(patient_index, img_size, img_scale=1.0, mask=None, augment=False, mode=[]):\n",
    "    \"\"\"\n",
    "    Function to retrieve data from a single patient\n",
    "    \n",
    "    Inputs:\n",
    "    - patient_index = list of bigrfullnames identifying scans\n",
    "    - img_size = size of MRI images\n",
    "    - img_scale = scale of the MRI scans [default = 1]\n",
    "    - mask = mask image if necessary [default = None]\n",
    "    - augment = Boolean if data augmentation should be used [default = False]\n",
    "    - mode = train, validate or test (used to find appropriate data)\n",
    "    \n",
    "    Outputs:\n",
    "    - img_data = MRI data\n",
    "    - input2 = sex of patient\n",
    "    - label = dementia_label (event=1, no event=0)\n",
    "    - time = event time \n",
    "\n",
    "    \"\"\"\n",
    "    # Retrieve patient info and label(=SNP) of the patient\n",
    "    if mode == 'train':\n",
    "        patient_info = train_label_set.loc[patient_index]\n",
    "    elif mode == 'validate':\n",
    "        patient_info = validation_label_set.loc[patient_index]\n",
    "    elif mode == 'test':\n",
    "        patient_info = test_label_set.loc[patient_index]\n",
    "    \n",
    "    # Get patient label (incident dementia or not)\n",
    "    label = patient_info.get('dementia')\n",
    "    \n",
    "    # Get second input (sex)\n",
    "    input2 = patient_info.get('sex')    \n",
    "    \n",
    "    # Get event time\n",
    "    time = patient_info.get('event_time')\n",
    "\n",
    "    # Get image\n",
    "    patient_filename = patient_index.strip()+'_GM_to_template_GM_mod.nii.gz'\n",
    "    img = nib.load(IMAGE_DIR+patient_filename)\n",
    "                 \n",
    "        \n",
    "    img_data = img.get_data()\n",
    "    # Apply mask to imagedata (if requested)\n",
    "    if mask is not None:\n",
    "#        img_data = img_data*mask+(mask-1.0)\n",
    "        img_data = img_data*mask\n",
    "        img_data = zerocrop_img(img_data)\n",
    "\n",
    "    \n",
    "    # Rescale imagedata (if requested)\n",
    "    if img_scale < 1.0:\n",
    "        img_data = resize_img(img_data, img_size)\n",
    "    \n",
    "    return np.array(img_data), np.array(int(input2)), label, time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(patients, img_size, img_scale=1.0, mask=None, augment=False, mode=[]):\n",
    "    \"\"\"\n",
    "    iterate through a batch of patients and get the corresponding data\n",
    "    \n",
    "    Input: \n",
    "    - patients = list of bigrfullnames identifying scans\n",
    "    - img_size = size of MRI images\n",
    "    - img_scale = scale of the MRI scans [default = 1]\n",
    "    - mask = mask image if necessary [default = None]\n",
    "    - augment = Boolean if data augmentation should be used [default = False]\n",
    "    - mode\n",
    "    \n",
    "    Outputs:\n",
    "    - [input data] = covariates\n",
    "    - [label data] = label (incident dementia or not) and riskset of patient\n",
    "\n",
    "    \"\"\"    \n",
    "    #get data of each patient\n",
    "    img_data = []\n",
    "    label_data = []\n",
    "    time = []\n",
    "    sex = []\n",
    "    for patient in patients:\n",
    "        try:\n",
    "            x, x2, y, t = retrieve_data(patient, img_size, img_scale, mask, augment, mode)\n",
    "            img_data.append(x)\n",
    "            sex.append(x2)\n",
    "            label_data.append(y)\n",
    "            time.append(t)\n",
    "        except KeyError as e:\n",
    "            print('\\nERROR: No label found for file {}'.format(patient))\n",
    "        except IOError as e:            \n",
    "            print('\\nERROR: Problem loading file {}. File probably corrupted.'.format(patient))\n",
    "            \n",
    "    # Make riskset\n",
    "    label_riskset = generate_riskset(np.array(time))\n",
    "    #convert to correct input format for network\n",
    "    img_data = np.array(img_data)\n",
    "    img_data = np.reshape(img_data,(-1, 160, 192, 144, 1))\n",
    "\n",
    "    sex_data = np.array(sex)\n",
    "    \n",
    "    label_data = np.array([label_data])\n",
    "    label_riskset = np.array(label_riskset)\n",
    "    \n",
    "    label_data = label_data.transpose()\n",
    "    label_data_out = np.hstack((label_data,label_riskset))\n",
    "\n",
    "    return ([img_data, sex_data], [label_data_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(patient_list, img_size, batch_size, img_scale=1.0, mask=None, augment=False, mode=[], shuffle=True):\n",
    "    \"\"\"\n",
    "    Provides the inputs and the label to the convolutional network during training\n",
    "    \n",
    "    Input:\n",
    "    - patient_list = list of bigrfullnames identifying scans\n",
    "    - img_size = size of MRI images\n",
    "    - batch_size = size of batch used in training\n",
    "    - img_scale = scale of the MRI scans [default = 1]\n",
    "    - mask = mask image if necessary [default = None]\n",
    "    - augment = Boolean if data augmentation should be used [default = False]\n",
    "    \n",
    "    Output:\n",
    "    - Data = continous data output for batches used in training the network\n",
    "\n",
    "    \"\"\"\n",
    "    while 1:\n",
    "        if shuffle:\n",
    "            #shuffle list/order of patients\n",
    "            pl_shuffled = random.sample(patient_list, len(patient_list))\n",
    "            #divide list of patients into batches\n",
    "            batch_size = int(batch_size)\n",
    "            patient_sublist = [pl_shuffled[p:p+batch_size] for p in range(0, len(pl_shuffled), batch_size)]\n",
    "        else:\n",
    "            batch_size = int(batch_size)\n",
    "            patient_sublist = [patient_list[p:p+batch_size] for p in range(0, len(patient_list), batch_size)]\n",
    "        count = 0\n",
    "        data = []\n",
    "        for batch in range(0, len(patient_sublist)):         \n",
    "            #get the data of a batch samples/patients\n",
    "            data.append(generate_batch(patient_sublist[batch], img_size, img_scale, mask, augment, mode))\n",
    "            count = count + len(patient_sublist[batch])\n",
    "            #yield the data and pop for memory clearing\n",
    "            yield data.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crops the zero-margin of a 3D image (based on mask)\n",
    "def zerocrop_img(img, set_crop=False, padding=False):\n",
    "    global crop_indeces\n",
    "    \n",
    "    #set crop locations if there are none yet or if requested\n",
    "    if (crop_indeces is None) or (set_crop):\n",
    "        # argwhere will give you the coordinates of every non-zero point\n",
    "        true_data = np.argwhere(img)\n",
    "        # take the smallest points and use them as the top left of your crop\n",
    "        top_left = true_data.min(axis=0)\n",
    "        # take the largest points and use them as the bottom right of your crop\n",
    "        bottom_right = true_data.max(axis=0)\n",
    "        crop_indeces = [top_left, bottom_right+1]  # plus 1 because slice isn't inclusive\n",
    "        \n",
    "        print('crop set to x[{}:{}], y[{}:{}], z[{}:{}]'.format(crop_indeces[0][0], crop_indeces[1][0], \n",
    "                                                                crop_indeces[0][1], crop_indeces[1][1], \n",
    "                                                                crop_indeces[0][2], crop_indeces[1][2]))\n",
    "\n",
    "        if padding == True:\n",
    "            shape = crop_indeces[1]-crop_indeces[0]\n",
    "            bottom_unet = shape.astype(float)/2/2**3\n",
    "            top_unet = np.ceil(bottom_unet)*2*2**3\n",
    "            padding = (top_unet-shape)/2\n",
    "            print('applying [{},{},{}] padding to image..'.format(padding[0], padding[1], padding[2]))\n",
    "            padding_l = padding.astype(int)\n",
    "            padding_r = np.ceil(padding).astype(int)\n",
    "            crop_indeces[0] -= padding_l\n",
    "            crop_indeces[1] += padding_r\n",
    "\n",
    "            print('crop set to x[{}:{}], y[{}:{}], z[{}:{}]'.format(crop_indeces[0][0], crop_indeces[1][0], \n",
    "                                                                    crop_indeces[0][1], crop_indeces[1][1], \n",
    "                                                                    crop_indeces[0][2], crop_indeces[1][2]))\n",
    "    \n",
    "    try:\n",
    "        cropped_img = img[crop_indeces[0][0]:crop_indeces[1][0],  \n",
    "                          crop_indeces[0][1]:crop_indeces[1][1],\n",
    "                          crop_indeces[0][2]:crop_indeces[1][2]]\n",
    "        return cropped_img\n",
    "    except ValueError:\n",
    "        print('ERROR: No crop_indeces defined for zerocrop. Returning full image...')\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_riskset(event_times):\n",
    "    \"\"\"\n",
    "    Generates the riskset for every individual. Riskset is the set of individuals that have a \n",
    "    longer event time and are thus at risk of experiencing the event : Tj>=Ti\n",
    "    \n",
    "    Input:\n",
    "    - label_data = dataframe with file name, event times and other labels that do not get used\n",
    "    \n",
    "    Output:\n",
    "    - riskset = square matrix in which row i is the riskset of individual i compared to all \n",
    "    individuals j. Entry is true if Tj>=Ti, so individual j is 'at risk'.\n",
    "    \"\"\"\n",
    "\n",
    "    o = np.argsort(-event_times, kind=\"mergesort\")\n",
    "    n_samples = len(event_times)\n",
    "    risk_set = np.zeros((n_samples, n_samples), dtype=np.bool_)\n",
    "    for i_org, i_sort in enumerate(o):\n",
    "        ti = event_times[i_sort]\n",
    "        k = i_org\n",
    "        while k < n_samples and ti == event_times[o[k]]:\n",
    "            k += 1\n",
    "        risk_set[i_sort, o[:k]] = True\n",
    "    return risk_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A small test\n",
    "ages = []\n",
    "birthdates = ['11/04/1930','15/05/1952','26/01/1943','18/06/1944']\n",
    "\n",
    "for date in  birthdates:\n",
    "    birthdate = datetime.strptime(date, '%d/%m/%Y')\n",
    "    scandate = datetime.strptime('8/12/2020', '%d/%m/%Y')\n",
    "    ages.append((scandate-birthdate).days/ 365.25)\n",
    "\n",
    "\n",
    "test_set = ['ergomri_1604_v_1975212_1069','ergomri_783_mri_9973399_563','ergomri_1391_m_4009993_908','ergo5mri_1420_9319504_7837'] \n",
    "data = {'bigrfullname':  ['ergomri_1604_v_1975212_1069','ergomri_783_mri_9973399_563','ergomri_1391_m_4009993_908','ergo5mri_1420_9319504_7837'],\n",
    "        'age': ages,\n",
    "        'sex': [1,0,0,1]\n",
    "        }\n",
    "\n",
    "test_label_set = pd.DataFrame (data, columns = ['bigrfullname','age','sex','dementia','event_time'])\n",
    "test_label_set = test_label_set.set_index('bigrfullname')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>dementia</th>\n",
       "      <th>event_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bigrfullname</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ergomri_1604_v_1975212_1069</th>\n",
       "      <td>90.661191</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ergomri_783_mri_9973399_563</th>\n",
       "      <td>68.566735</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ergomri_1391_m_4009993_908</th>\n",
       "      <td>77.867214</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ergo5mri_1420_9319504_7837</th>\n",
       "      <td>76.473648</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   age  sex dementia event_time\n",
       "bigrfullname                                                   \n",
       "ergomri_1604_v_1975212_1069  90.661191    1      NaN        NaN\n",
       "ergomri_783_mri_9973399_563  68.566735    0      NaN        NaN\n",
       "ergomri_1391_m_4009993_908   77.867214    0      NaN        NaN\n",
       "ergo5mri_1420_9319504_7837   76.473648    1      NaN        NaN"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/trinity/home/jyu/yjvenv/lib/python3.7/site-packages/ipykernel_launcher.py:13: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
      "\n",
      "* deprecated from version: 3.0\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crop set to x[26:171], y[28:209], z[19:156]\n",
      "applying [7.5,5.5,3.5] padding to image..\n",
      "crop set to x[19:179], y[23:215], z[16:160]\n",
      "data shape: [160, 192, 144]\n"
     ]
    }
   ],
   "source": [
    "#initialize\n",
    "mask_file = 'Brain_GM_mask_1mm_MNI_kNN_conservative.nii.gz' #None\n",
    "#init_preprocessing(prepdata_name)\n",
    "use_padding = True\n",
    "crop_indeces = None\n",
    "img_scale = 1\n",
    "\n",
    "#initialize\n",
    "#init_preprocessing(prepdata_name)\n",
    "\n",
    "#setup image_size\n",
    "if mask_file is not None:\n",
    "    mask = nib.load(MASK_DIR+mask_file).get_data()\n",
    "    #when applying a mask, initialize zerocropping\n",
    "    img_size = np.array(np.array(zerocrop_img(mask, True, padding=use_padding)).shape)\n",
    "else:\n",
    "    mask = None\n",
    "    img_size = np.array(np.array(nib.load(IMAGE_DIR+os.listdir(IMAGE_DIR)[0]).get_data()).shape)\n",
    "\n",
    "img_size = [int(math.ceil(img_d)) for img_d in img_size*img_scale]\n",
    "print('data shape:', img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(WANG_DIR+'model_age_5h.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 160, 192, 14 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_1 (Conv3D)               (None, 80, 96, 72, 3 4032        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 80, 96, 72, 3 128         conv3d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 80, 96, 72, 3 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_2 (Conv3D)               (None, 80, 96, 72, 3 27680       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 80, 96, 72, 3 128         conv3d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 80, 96, 72, 3 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3D)  (None, 40, 48, 36, 3 0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_3 (Conv3D)               (None, 40, 48, 36, 4 41520       max_pooling3d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 40, 48, 36, 4 192         conv3d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 40, 48, 36, 4 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_4 (Conv3D)               (None, 40, 48, 36, 4 62256       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 40, 48, 36, 4 192         conv3d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 40, 48, 36, 4 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3D)  (None, 20, 24, 18, 4 0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_5 (Conv3D)               (None, 20, 24, 18, 6 83008       max_pooling3d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 20, 24, 18, 6 256         conv3d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 20, 24, 18, 6 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_6 (Conv3D)               (None, 20, 24, 18, 6 110656      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 20, 24, 18, 6 256         conv3d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 20, 24, 18, 6 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3D)  (None, 10, 12, 9, 64 0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_7 (Conv3D)               (None, 10, 12, 9, 80 138320      max_pooling3d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 10, 12, 9, 80 320         conv3d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 10, 12, 9, 80 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_8 (Conv3D)               (None, 10, 12, 9, 80 172880      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 10, 12, 9, 80 320         conv3d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 10, 12, 9, 80 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling3d_1 (Glo (None, 80)           0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 81)           0           global_average_pooling3d_1[0][0] \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           2624        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            33          dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 644,801\n",
      "Trainable params: 643,905\n",
      "Non-trainable params: 896\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/trinity/home/jyu/yjvenv/lib/python3.7/site-packages/ipykernel_launcher.py:44: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
      "\n",
      "* deprecated from version: 3.0\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 307ms/step\n"
     ]
    }
   ],
   "source": [
    "test_predictions = model.predict_generator(data_generator(list(test_set), img_size, batch_size, img_scale, mask=mask, mode='test',shuffle=False),\n",
    "                                             steps=int(math.ceil(float(len(test_set))/batch_size)),\n",
    "                                             max_queue_size=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'Patient': test_set,\n",
    "        'Real age':  ages,\n",
    "        'Predicted age': test_predictions.tolist()        }\n",
    "\n",
    "result_df = pd.DataFrame(results, columns = ['Patient','Real age','Predicted age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>Real age</th>\n",
       "      <th>Predicted age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ergomri_1604_v_1975212_1069</td>\n",
       "      <td>90.661191</td>\n",
       "      <td>[78.38008117675781]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ergomri_783_mri_9973399_563</td>\n",
       "      <td>68.566735</td>\n",
       "      <td>[68.54951477050781]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ergomri_1391_m_4009993_908</td>\n",
       "      <td>77.867214</td>\n",
       "      <td>[81.1343765258789]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ergo5mri_1420_9319504_7837</td>\n",
       "      <td>76.473648</td>\n",
       "      <td>[76.70735168457031]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Patient   Real age        Predicted age\n",
       "0  ergomri_1604_v_1975212_1069  90.661191  [78.38008117675781]\n",
       "1  ergomri_783_mri_9973399_563  68.566735  [68.54951477050781]\n",
       "2   ergomri_1391_m_4009993_908  77.867214   [81.1343765258789]\n",
       "3   ergo5mri_1420_9319504_7837  76.473648  [76.70735168457031]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
