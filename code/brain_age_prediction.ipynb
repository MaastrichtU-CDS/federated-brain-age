{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 01:45:11.886102: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "import csv\n",
    "import nipy\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from dateutil import relativedelta\n",
    "import gc\n",
    "\n",
    "from scipy import ndimage as nd\n",
    "import scipy.stats as stats\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "# -------------------  start importing keras module ---------------------\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Conv3D, MaxPooling3D, BatchNormalization, Dropout, GlobalAveragePooling3D\n",
    "from tensorflow.keras.layers import Input, concatenate, multiply, add, Reshape, Lambda\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR = 'path to VBM image directory'\n",
    "MASK_DIR = 'path to Mask image directory'\n",
    "MODEL_DIR = 'path to load and save model/results'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model and training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track history\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def __init__(self, epochs, modelversion):\n",
    "        self.ne = epochs\n",
    "        self.mv = modelversion        \n",
    "    \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.batch_num = 0\n",
    "        self.batch_losses = []\n",
    "        self.epoch_losses = []\n",
    "\n",
    "        print('Start training ...')\n",
    "        \n",
    "        self.stats = ['loss'] #TODO: check\n",
    "        self.logs = [{} for _ in range(self.ne)]\n",
    "\n",
    "        self.evolution_file = 'evolution_'+self.mv+'.csv'\n",
    "        with open(MODEL_DIR+self.evolution_file, \"w\") as f:\n",
    "            f.write(';'.join(self.stats + ['val_'+s for s in self.stats]) + \"\\n\")\n",
    "        \n",
    "        self.progress_file = 'training_progress_'+self.mv+'.out'\n",
    "        with open(MODEL_DIR+self.progress_file, \"w\") as f:\n",
    "            f.write('Start training ...\\n')\n",
    "            \n",
    "    def on_batch_end(self, epoch, logs={}):\n",
    "        self.batch_losses.append(logs.get('loss'))\n",
    "\n",
    "        \n",
    "        with open(MODEL_DIR+self.progress_file, \"a\") as f:\n",
    "            f.write('  >> batch {} >> loss:{} \\r'.format(self.batch_num, self.batch_losses[-1]))\n",
    "        \n",
    "        self.batch_num += 1\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.batch_num = 0\n",
    "        self.epoch_losses.append(logs.get('loss'))\n",
    "        \n",
    "        \n",
    "#        print('\\n    >>> logs:', logs)\n",
    "        self.logs[epoch] = logs\n",
    "#        evolution_file = 'evolution_'+self.mv+'.csv'\n",
    "        loss_fig = 'loss_'+self.mv+'.png'\n",
    "        \n",
    "        with open(MODEL_DIR+self.evolution_file, \"a\") as myfile:\n",
    "            num_stats = len(self.stats)\n",
    "            \n",
    "            plt.figure(figsize=(40, num_stats*15))\n",
    "            plt.suptitle(loss_fig, fontsize=34, fontweight='bold')\n",
    "\n",
    "            gs = gridspec.GridSpec(len(self.stats), 2) \n",
    "\n",
    "            last_losses = []\n",
    "            last_val_losses = []\n",
    "            for idx, stat in enumerate(self.stats):\n",
    "                losses = [self.logs[e][stat] for e in range(epoch+1)]\n",
    "                last_losses.append('{}'.format(losses[-1]))\n",
    "                val_losses = [self.logs[e]['val_'+stat] for e in range(epoch+1)]\n",
    "                last_val_losses.append('{}'.format(val_losses[-1]))\n",
    "\n",
    "                plt.subplot(gs[idx,0])\n",
    "                plt.ylabel(stat, fontsize=34)\n",
    "                plt.plot(range(0, epoch+1), losses, '-', color = 'b')\n",
    "                plt.plot(range(0, epoch+1), val_losses, '-', color = 'r')\n",
    "                plt.tick_params(axis='x', labelsize=30)\n",
    "                plt.tick_params(axis='y', labelsize=30)\n",
    "                plt.grid(True)\n",
    "\n",
    "                recent_n = 10\n",
    "                recent_losses = losses[-recent_n:]\n",
    "                recent_val_losses = val_losses[-recent_n:]\n",
    "                miny_range = 5\n",
    "                lowery = min([min(losses), recent_losses[-1]-miny_range, min(val_losses), recent_val_losses[-1]-miny_range])\n",
    "                uppery = max([max(recent_losses), recent_losses[-1]+miny_range, max(recent_val_losses), recent_val_losses[-1]+miny_range])\n",
    "                plt.subplot(gs[idx,1])\n",
    "                plt.ylabel(stat, fontsize=34)\n",
    "                plt.plot(range(0, epoch+1), losses, '-', color = 'b')\n",
    "                plt.plot(range(0, epoch+1), val_losses, '-', color = 'r')\n",
    "                plt.ylim(lowery, uppery)\n",
    "                plt.tick_params(axis='x', labelsize=30)\n",
    "                plt.tick_params(axis='y', labelsize=30)\n",
    "                plt.grid(True)\n",
    "                \n",
    "            myfile.write(';'.join(last_losses + last_val_losses) + '\\n')\n",
    "            try:                \n",
    "                plt.savefig(MODEL_DIR+loss_fig)\n",
    "            except Exception as inst:\n",
    "                print(type(inst))\n",
    "                print(inst)\n",
    "            plt.close()\n",
    "        \n",
    "\n",
    "        with open(MODEL_DIR+self.progress_file, \"a\") as f:\n",
    "            f.write('epoch {}/{}:\\n'.format(epoch, self.ne))\n",
    "            for idx, stat in enumerate(self.stats):\n",
    "                f.write('  {} = {}\\n  val_{} = {}\\n'.format(stat, last_losses[idx], stat, last_val_losses[idx]))\n",
    "\n",
    "        gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the best model on validation set\n",
    "def save_checkpoint(name, model):\n",
    "    save_model(name, model)\n",
    "    weights_file = 'model_'+name+'.h5'\n",
    "    return ModelCheckpoint(MODEL_DIR+weights_file, monitor='val_loss', verbose=0, save_best_only=True, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(name, model):\n",
    "    model_file = 'model_'+name+'.json'\n",
    "    # serialize model to JSON\n",
    "    with open(MODEL_DIR+model_file, 'w') as json_file:\n",
    "        json_file.write(model.to_json())\n",
    "    print('Saved model to '+MODEL_DIR+model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_history(name, history, score, sets, distrs):\n",
    "    history_file = 'history_'+name+'.h5'\n",
    "\n",
    "    f = h5py.File(MODEL_DIR+history_file, 'w')\n",
    "\n",
    "    f.create_dataset('batch_losses', data=history.batch_losses)\n",
    "    f.create_dataset('epoch_losses', data=history.epoch_losses)\n",
    "    f.create_dataset(\"score\", data=score)\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    print('Saved history to '+MODEL_DIR+history_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class imgZeropad:\n",
    "\n",
    "    def __init__(self, img, use_padding=False):\n",
    "        self.set_crop(img, use_padding)\n",
    "    \n",
    "    #set crop locations\n",
    "    def set_crop(self, img, use_padding=False):\n",
    "        # argwhere will give you the coordinates of every non-zero point\n",
    "        true_data = np.argwhere(img)\n",
    "        # take the smallest points and use them as the top left of your crop\n",
    "        top_left = true_data.min(axis=0)\n",
    "        # take the largest points and use them as the bottom right of your crop\n",
    "        bottom_right = true_data.max(axis=0)\n",
    "        crop_indeces = [top_left, bottom_right+1]  # plus 1 because slice isn't inclusive\n",
    "\n",
    "        print('crop set to x[{}:{}], y[{}:{}], z[{}:{}]'.format(crop_indeces[0][0], crop_indeces[1][0], \n",
    "                                                                crop_indeces[0][1], crop_indeces[1][1], \n",
    "                                                                crop_indeces[0][2], crop_indeces[1][2]))\n",
    "\n",
    "        if use_padding == True:\n",
    "            shape = crop_indeces[1]-crop_indeces[0]\n",
    "            bottom_net = shape.astype(float)/2/2**3\n",
    "            top_net = np.ceil(bottom_net)*2*2**3\n",
    "            padding = (top_net-shape)/2\n",
    "            print('applying [{},{},{}] padding to image..'.format(padding[0], padding[1], padding[2]))\n",
    "            padding_l = padding.astype(int)\n",
    "            padding_r = np.ceil(padding).astype(int)\n",
    "            crop_indeces[0] -= padding_l\n",
    "            crop_indeces[1] += padding_r\n",
    "\n",
    "            print('crop set to x[{}:{}], y[{}:{}], z[{}:{}]'.format(crop_indeces[0][0], crop_indeces[1][0], \n",
    "                                                                    crop_indeces[0][1], crop_indeces[1][1], \n",
    "                                                                    crop_indeces[0][2], crop_indeces[1][2]))\n",
    "        else:\n",
    "            padding = np.zeros(3)\n",
    "        self.crop_indeces = crop_indeces\n",
    "        self.padding = padding\n",
    "        \n",
    "        shape = crop_indeces[1]-crop_indeces[0]\n",
    "        self.img_size = (shape[0], shape[1], shape[2])\n",
    "\n",
    "    #crop according to crop_indeces\n",
    "    def zerocrop_img(self, img, augment=False):\n",
    "        if augment:\n",
    "            randx = np.random.rand(3)*2-1\n",
    "            new_crop = self.crop_indeces+(self.padding*randx).astype(int)\n",
    "\n",
    "            cropped_img = img[new_crop[0][0]:new_crop[1][0],  \n",
    "                              new_crop[0][1]:new_crop[1][1],\n",
    "                              new_crop[0][2]:new_crop[1][2]]\n",
    "\n",
    "            flip_axis = np.random.rand(3)\n",
    "            if round(flip_axis[0]):\n",
    "                cropped_img = cropped_img[::-1,:,:]\n",
    "            if round(flip_axis[1]):\n",
    "                cropped_img = cropped_img[:,::-1,:]\n",
    "            if round(flip_axis[2]):\n",
    "                cropped_img = cropped_img[:,:,::-1]\n",
    "                \n",
    "        else:\n",
    "            cropped_img = img[self.crop_indeces[0][0]:self.crop_indeces[1][0],  \n",
    "                              self.crop_indeces[0][1]:self.crop_indeces[1][1],\n",
    "                              self.crop_indeces[0][2]:self.crop_indeces[1][2]]\n",
    "            \n",
    "        return cropped_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crops the zero-margin of a 3D image (based on mask)\n",
    "def zerocrop_img(img, set_crop=False, padding=False):\n",
    "    global crop_indeces\n",
    "    \n",
    "    #set crop locations if there are none yet or if requested\n",
    "    if (crop_indeces is None) or (set_crop):\n",
    "        # argwhere will give you the coordinates of every non-zero point\n",
    "        true_data = np.argwhere(img)\n",
    "        # take the smallest points and use them as the top left of your crop\n",
    "        top_left = true_data.min(axis=0)\n",
    "        # take the largest points and use them as the bottom right of your crop\n",
    "        bottom_right = true_data.max(axis=0)\n",
    "        crop_indeces = [top_left, bottom_right+1]  # plus 1 because slice isn't inclusive\n",
    "        \n",
    "        print('crop set to x[{}:{}], y[{}:{}], z[{}:{}]'.format(crop_indeces[0][0], crop_indeces[1][0], \n",
    "                                                                crop_indeces[0][1], crop_indeces[1][1], \n",
    "                                                                crop_indeces[0][2], crop_indeces[1][2]))\n",
    "\n",
    "        if padding == True:\n",
    "            shape = crop_indeces[1]-crop_indeces[0]\n",
    "            bottom_unet = shape.astype(float)/2/2**3\n",
    "            top_unet = np.ceil(bottom_unet)*2*2**3\n",
    "            padding = (top_unet-shape)/2\n",
    "            print('applying [{},{},{}] padding to image..'.format(padding[0], padding[1], padding[2]))\n",
    "            padding_l = padding.astype(int)\n",
    "            padding_r = np.ceil(padding).astype(int)\n",
    "            crop_indeces[0] -= padding_l\n",
    "            crop_indeces[1] += padding_r\n",
    "\n",
    "            print('crop set to x[{}:{}], y[{}:{}], z[{}:{}]'.format(crop_indeces[0][0], crop_indeces[1][0], \n",
    "                                                                    crop_indeces[0][1], crop_indeces[1][1], \n",
    "                                                                    crop_indeces[0][2], crop_indeces[1][2]))\n",
    "    \n",
    "    try:\n",
    "        cropped_img = img[crop_indeces[0][0]:crop_indeces[1][0],  \n",
    "                          crop_indeces[0][1]:crop_indeces[1][1],\n",
    "                          crop_indeces[0][2]:crop_indeces[1][2]]\n",
    "        return cropped_img\n",
    "    except ValueError:\n",
    "        print('ERROR: No crop_indeces defined for zerocrop. Returning full image...')\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN image processing by batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_data(patient_index, img_size, img_scale=1.0, mask=None, augment=False, mode=[]):\n",
    "    \"\"\"\n",
    "    Function to retrieve data from a single patient\n",
    "    \n",
    "    Inputs:\n",
    "    - patient_index = list of bigrfullnames identifying scans\n",
    "    - img_size = size of MRI images\n",
    "    - img_scale = scale of the MRI scans [default = 1]\n",
    "    - mask = mask image if necessary [default = None]\n",
    "    - augment = Boolean if data augmentation should be used [default = False]\n",
    "    - mode = train, validate or test (used to find appropriate data)\n",
    "    \n",
    "    Outputs:\n",
    "    - img_data = MRI data\n",
    "    - input2 = sex\n",
    "    - label = age\n",
    "\n",
    "    \"\"\"\n",
    "    # Retrieve patient info and label(=SNP) of the patient\n",
    "    if mode == 'train':\n",
    "        patient_info = train_label_set.loc[patient_index]\n",
    "    elif mode == 'validate':\n",
    "        patient_info = validation_label_set.loc[patient_index]\n",
    "    elif mode == 'test':\n",
    "        patient_info = test_label_set.loc[patient_index]\n",
    "    else: # validation set might not use validation flag\n",
    "        patient_info = validation_label_set.loc[patient_index]\n",
    "    \n",
    "    # Get patient label (incident dementia or not)\n",
    "    label = patient_info.get('age')\n",
    "    \n",
    "    # Get second input (sex)\n",
    "    input2 = patient_info.get('sex')    \n",
    "    \n",
    "\n",
    "    # Get image\n",
    "    patient_filename = patient_index.strip()+'_GM_to_template_GM_mod.nii.gz'\n",
    "    img = nib.load(IMAGE_DIR+patient_filename)  \n",
    "    img_data = img.get_data()\n",
    "    \n",
    "    # Apply mask to imagedata (if requested)\n",
    "    if mask is not None:\n",
    "        img_data = img_data*mask\n",
    "        img_data = zerocrop_img(img_data)\n",
    "\n",
    "    # Rescale imagedata (if requested)\n",
    "    if img_scale < 1.0:\n",
    "        img_data = resize_img(img_data, img_size)\n",
    "    \n",
    "    return np.array(img_data), np.array(int(input2)), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(patients, img_size, img_scale=1.0, mask=None, augment=False, mode=[]):\n",
    "    \"\"\"\n",
    "    iterate through a batch of patients and get the corresponding data\n",
    "    \n",
    "    Input: \n",
    "    - patients = list of bigrfullnames identifying scans\n",
    "    - img_size = size of MRI images\n",
    "    - img_scale = scale of the MRI scans [default = 1]\n",
    "    - mask = mask image if necessary [default = None]\n",
    "    - augment = Boolean if data augmentation should be used [default = False]\n",
    "    - mode\n",
    "    \n",
    "    Outputs:\n",
    "    - [input data] = sex\n",
    "    - [label data] = age\n",
    "\n",
    "    \"\"\"    \n",
    "    #get data of each patient\n",
    "    img_data = []\n",
    "    label_data = []\n",
    "    sex = []\n",
    "    for patient in patients:\n",
    "        try:\n",
    "            x, x2, y = retrieve_data(patient, img_size, img_scale, mask, augment, mode)\n",
    "            img_data.append(x)\n",
    "            sex.append(x2)\n",
    "            label_data.append(y)\n",
    "        except KeyError as e:\n",
    "            print('\\nERROR: No label found for file {}'.format(patient))\n",
    "        except IOError as e:            \n",
    "            print('\\nERROR: Problem loading file {}. File probably corrupted.'.format(patient))\n",
    "            \n",
    "\n",
    "    #convert to correct input format for network\n",
    "    img_data = np.array(img_data)\n",
    "    img_data = np.reshape(img_data,(-1, 160, 192, 144, 1))\n",
    "\n",
    "    sex_data = np.array(sex)\n",
    "    \n",
    "    label_data = np.array(label_data)\n",
    "\n",
    "\n",
    "    return ([img_data, sex_data], [label_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(patient_list, img_size, batch_size, img_scale=1.0, mask=None, augment=False, mode=[], shuffle=True):\n",
    "    \"\"\"\n",
    "    Provides the inputs and the label to the convolutional network during training\n",
    "    \n",
    "    Input:\n",
    "    - patient_list = list of bigrfullnames identifying scans\n",
    "    - img_size = size of MRI images\n",
    "    - batch_size = size of batch used in training\n",
    "    - img_scale = scale of the MRI scans [default = 1]\n",
    "    - mask = mask image if necessary [default = None]\n",
    "    - augment = Boolean if data augmentation should be used [default = False]\n",
    "    \n",
    "    Output:\n",
    "    - Data = continous data output for batches used in training the network\n",
    "\n",
    "    \"\"\"\n",
    "    while 1:\n",
    "        if shuffle:\n",
    "            #shuffle list/order of patients\n",
    "            pl_shuffled = random.sample(patient_list, len(patient_list))\n",
    "            #divide list of patients into batches\n",
    "            batch_size = int(batch_size)\n",
    "            patient_sublist = [pl_shuffled[p:p+batch_size] for p in range(0, len(pl_shuffled), batch_size)]\n",
    "        else:\n",
    "            batch_size = int(batch_size)\n",
    "            patient_sublist = [patient_list[p:p+batch_size] for p in range(0, len(patient_list), batch_size)]\n",
    "        count = 0\n",
    "        data = []\n",
    "        for batch in range(0, len(patient_sublist)):         \n",
    "            #get the data of a batch samples/patients\n",
    "            data.append(generate_batch(patient_sublist[batch], img_size, img_scale, mask, augment, mode))\n",
    "            count = count + len(patient_sublist[batch])\n",
    "            #yield the data and pop for memory clearing\n",
    "            yield data.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A small test\n",
    "ages = []\n",
    "birthdates = ['11/04/1930','15/05/1952','26/01/1943','18/06/1944']\n",
    "\n",
    "for date in  birthdates:\n",
    "    birthdate = datetime.strptime(date, '%d/%m/%Y')\n",
    "    scandate = datetime.strptime('8/12/2020', '%d/%m/%Y')\n",
    "    ages.append((scandate-birthdate).days/ 365.25)\n",
    "\n",
    "\n",
    "data_set = ['ergomri_1604_v_1975212_1069','ergomri_783_mri_9973399_563','ergomri_1391_m_4009993_908','ergo5mri_1420_9319504_7837'] \n",
    "data = {'bigrfullname':  ['ergomri_1604_v_1975212_1069','ergomri_783_mri_9973399_563','ergomri_1391_m_4009993_908','ergo5mri_1420_9319504_7837'],\n",
    "        'age': ages,\n",
    "        'sex': [1,0,0,1]\n",
    "        }\n",
    "\n",
    "data_label_set = pd.DataFrame (data, columns = ['bigrfullname','age','sex'])\n",
    "data_label_set = data_label_set.set_index('bigrfullname')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ergomri_1604_v_1975212_1069',\n",
       " 'ergomri_783_mri_9973399_563',\n",
       " 'ergomri_1391_m_4009993_908',\n",
       " 'ergo5mri_1420_9319504_7837']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bigrfullname</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ergomri_1604_v_1975212_1069</th>\n",
       "      <td>90.661191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ergomri_783_mri_9973399_563</th>\n",
       "      <td>68.566735</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ergomri_1391_m_4009993_908</th>\n",
       "      <td>77.867214</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ergo5mri_1420_9319504_7837</th>\n",
       "      <td>76.473648</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   age  sex\n",
       "bigrfullname                               \n",
       "ergomri_1604_v_1975212_1069  90.661191    1\n",
       "ergomri_783_mri_9973399_563  68.566735    0\n",
       "ergomri_1391_m_4009993_908   77.867214    0\n",
       "ergo5mri_1420_9319504_7837   76.473648    1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_label_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Preparing datasets---\n",
      "Keras backend: tensorflow\n",
      "train samples: 4\n",
      "validation samples: 4\n",
      "test samples: 4\n"
     ]
    }
   ],
   "source": [
    "#split to train/validation/test set\n",
    "\n",
    "print('--- Preparing datasets---')\n",
    "\n",
    "print('Keras backend: '+keras.backend.backend())\n",
    "\n",
    "#label dataframe of patients (here we just use a informal train/validation/test set for convenience)\n",
    "train_label_set = data_label_set\n",
    "validation_label_set = data_label_set\n",
    "test_label_set = data_label_set\n",
    "\n",
    "#list of patients\n",
    "train_set = data_set\n",
    "validation_set = data_set\n",
    "test_set = data_set\n",
    "\n",
    "#print info per set\n",
    "train_size = len(train_label_set)\n",
    "print('train samples: {}'.format(train_size))\n",
    "\n",
    "validation_size = len(validation_label_set)\n",
    "print('validation samples: {}'.format(validation_size))\n",
    "\n",
    "test_size = len(test_label_set)\n",
    "print('test samples: {}'.format(test_size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Train model from scratch\n",
    "\n",
    "# def cnn_model(input_shape):\n",
    "\n",
    "#     #left input branch ------------------------\n",
    "#     input1 = Input(input_shape)\n",
    "\n",
    "#     c1 = Conv3D(32, kernel_size=(5,5,5), strides=(2,2,2), padding='same')(input1)\n",
    "#     c1 = BatchNormalization()(c1)\n",
    "#     c1 = Activation('relu')(c1)\n",
    "    \n",
    "#     c2 = Conv3D(32, (3,3,3), strides=(1,1,1), padding='same')(c1)\n",
    "#     c2 = BatchNormalization()(c2)\n",
    "#     c2 = Activation('relu')(c2)\n",
    "#     p2 = MaxPooling3D(pool_size=(2, 2, 2))(c2)\n",
    "    \n",
    "#     c3 = Conv3D(48, (3,3,3), strides=(1,1,1), padding='same')(p2)\n",
    "#     c3 = BatchNormalization()(c3)\n",
    "#     c3 = Activation('relu')(c3)\n",
    "    \n",
    "#     c4 = Conv3D(48, (3,3,3), strides=(1,1,1), padding='same')(c3)\n",
    "#     c4 = BatchNormalization()(c4)\n",
    "#     c4 = Activation('relu')(c4)\n",
    "#     p4 = MaxPooling3D(pool_size=(2, 2, 2))(c4)\n",
    "    \n",
    "#     c5 = Conv3D(64, (3,3,3), strides=(1,1,1), padding='same')(p4)\n",
    "#     c5 = BatchNormalization()(c5)\n",
    "#     c5 = Activation('relu')(c5)\n",
    "    \n",
    "#     c6 = Conv3D(64, (3,3,3), strides=(1,1,1), padding='same')(c5)\n",
    "#     c6 = BatchNormalization()(c6)\n",
    "#     c6 = Activation('relu')(c6)\n",
    "#     p6 = MaxPooling3D(pool_size=(2, 2, 2))(c6)\n",
    "\n",
    "#     c7 = Conv3D(80, (3,3,3), strides=(1,1,1), padding='same')(p6)\n",
    "#     c7 = BatchNormalization()(c7)\n",
    "#     c7 = Activation('relu')(c7)\n",
    "    \n",
    "#     c8 = Conv3D(80, (3,3,3), strides=(1,1,1), padding='same')(c7)\n",
    "#     c8 = BatchNormalization()(c8)\n",
    "#     c8 = Activation('relu')(c8)\n",
    "\n",
    "#     x1 = GlobalAveragePooling3D()(c8)\n",
    "\n",
    "#     #right input branch ------------------------\n",
    "#     input2 = Input((1,))\n",
    "\n",
    "#     #merging braches into final model ----------\n",
    "#     y1 = concatenate([x1, input2])   # other modes: multiply, concatenate, dot\n",
    "    \n",
    "#     y2 = Dense(32, activation='relu')(y1)\n",
    "#     y2 = Dropout(0.2)(y2)\n",
    "    \n",
    "#     final = Dense(1, activation='linear')(y2)\n",
    "\n",
    "#     model = Model(inputs=[input1, input2], outputs=final)\n",
    "    \n",
    "#     adam_opt = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0001)\n",
    "#     model.compile(loss='mean_squared_error',\n",
    "#                   optimizer=adam_opt,\n",
    "#                   metrics=['mae', 'mse'])\n",
    "    \n",
    "#     return model\n",
    "\n",
    "#model = cnn_model((160, 192, 144, 1))\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 01:51:43.175700: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ohpc/pub/easybuild/software/TensorFlow/2.2.0-fosscuda-2019b-Python-3.7.4/lib:/opt/ohpc/pub/easybuild/software/NCCL/2.4.8-gcccuda-2019b/lib:/opt/ohpc/pub/easybuild/software/cuDNN/7.6.4.38-gcccuda-2019b/lib64:/opt/ohpc/pub/easybuild/software/HDF5/1.10.5-gompic-2019b/lib:/opt/ohpc/pub/easybuild/software/Szip/2.1.1-GCCcore-8.3.0/lib:/opt/ohpc/pub/easybuild/software/SciPy-bundle/2019.10-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/numpy/core/lib:/opt/ohpc/pub/easybuild/software/SciPy-bundle/2019.10-fosscuda-2019b-Python-3.7.4/lib:/opt/ohpc/pub/easybuild/software/Python/3.7.4-GCCcore-8.3.0/lib:/opt/ohpc/pub/easybuild/software/libffi/3.2.1-GCCcore-8.3.0/lib64:/opt/ohpc/pub/easybuild/software/libffi/3.2.1-GCCcore-8.3.0/lib:/opt/ohpc/pub/easybuild/software/GMP/6.1.2-GCCcore-8.3.0/lib:/opt/ohpc/pub/easybuild/software/SQLite/3.29.0-GCCcore-8.3.0/lib:/opt/ohpc/pub/easybuild/software/Tcl/8.6.9-GCCcore-8.3.0/lib:/opt/ohpc/pub/easybuild/software/libreadline/8.0-GCCcore-8.3.0/lib:/opt/ohpc/pub/easybuild/software/ncurses/6.1-GCCcore-8.3.0/lib:/opt/ohpc/pub/easybuild/software/bzip2/1.0.8-GCCcore-8.3.0/lib:/opt/ohpc/pub/easybuild/software/ScaLAPACK/2.0.2-gompic-2019b/lib:/opt/ohpc/pub/easybuild/software/FFTW/3.3.8-gompic-2019b/lib:/opt/ohpc/pub/easybuild/software/OpenBLAS/0.3.7-GCC-8.3.0/lib:/opt/ohpc/pub/easybuild/software/OpenMPI/3.1.4-gcccuda-2019b/lib:/opt/ohpc/pub/easybuild/software/hwloc/1.11.12-GCCcore-8.3.0/lib:/opt/ohpc/pub/easybuild/software/libpciaccess/0.14-GCCcore-8.3.0/lib:/opt/ohpc/pub/easybuild/software/libxml2/2.9.9-GCCcore-8.3.0/lib:/opt/ohpc/pub/easybuild/software/XZ/5.2.4-GCCcore-8.3.0/lib:/opt/ohpc/pub/easybuild/software/numactl/2.0.12-GCCcore-8.3.0/lib:/opt/ohpc/pub/easybuild/software/CUDA/10.1.243-GCC-8.3.0/nvvm/lib64:/opt/ohpc/pub/easybuild/software/CUDA/10.1.243-GCC-8.3.0/extras/CUPTI/lib64:/opt/ohpc/pub/easybuild/software/CUDA/10.1.243-GCC-8.3.0/lib64:/opt/ohpc/pub/easybuild/software/binutils/2.32-GCCcore-8.3.0/lib:/opt/ohpc/pub/easybuild/software/zlib/1.2.11-GCCcore-8.3.0/lib:/opt/ohpc/pub/easybuild/software/GCCcore/8.3.0/lib64:/opt/ohpc/pub/easybuild/software/GCCcore/8.3.0/lib\n",
      "2022-02-17 01:51:43.175754: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-02-17 01:51:43.175809: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (rad-hpc-master-001): /proc/driver/nvidia/version does not exist\n",
      "2022-02-17 01:51:43.180543: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 160, 192, 14 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_1 (Conv3D)               (None, 80, 96, 72, 3 4032        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 80, 96, 72, 3 128         conv3d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 80, 96, 72, 3 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_2 (Conv3D)               (None, 80, 96, 72, 3 27680       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 80, 96, 72, 3 128         conv3d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 80, 96, 72, 3 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3D)  (None, 40, 48, 36, 3 0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_3 (Conv3D)               (None, 40, 48, 36, 4 41520       max_pooling3d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 40, 48, 36, 4 192         conv3d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 40, 48, 36, 4 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_4 (Conv3D)               (None, 40, 48, 36, 4 62256       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 40, 48, 36, 4 192         conv3d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 40, 48, 36, 4 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3D)  (None, 20, 24, 18, 4 0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_5 (Conv3D)               (None, 20, 24, 18, 6 83008       max_pooling3d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 20, 24, 18, 6 256         conv3d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 20, 24, 18, 6 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_6 (Conv3D)               (None, 20, 24, 18, 6 110656      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 20, 24, 18, 6 256         conv3d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 20, 24, 18, 6 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3D)  (None, 10, 12, 9, 64 0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_7 (Conv3D)               (None, 10, 12, 9, 80 138320      max_pooling3d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 10, 12, 9, 80 320         conv3d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 10, 12, 9, 80 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_8 (Conv3D)               (None, 10, 12, 9, 80 172880      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 10, 12, 9, 80 320         conv3d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 10, 12, 9, 80 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling3d_1 (Glo (None, 80)           0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 81)           0           global_average_pooling3d_1[0][0] \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           2624        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            33          dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 644,801\n",
      "Trainable params: 643,905\n",
      "Non-trainable params: 896\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Use pre-trained model: 'model_age_5h.h5' in models file (recommended)\n",
    "model = tf.keras.models.load_model(MODEL_DIR+'model_age_5h.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting initialization ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/trinity/home/jyu/yjvenv/lib/python3.7/site-packages/ipykernel_launcher.py:21: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
      "\n",
      "* deprecated from version: 3.0\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crop set to x[26:171], y[28:209], z[19:156]\n",
      "applying [7.5,5.5,3.5] padding to image..\n",
      "crop set to x[19:179], y[23:215], z[16:160]\n",
      "data shape: [160, 192, 144]\n"
     ]
    }
   ],
   "source": [
    "print('--- Starting initialization ---')\n",
    "\n",
    "#choose variables\n",
    "use_padding = True\n",
    "crop_indeces = None\n",
    "augment_train = True\n",
    "img_scale = 1.0\n",
    "\n",
    "batch_size = 1\n",
    "patients_per_epoch = 4 #steps_per_epoch = patients_per_epoch/batch_size\n",
    "epochs = 4\n",
    "\n",
    "\n",
    "mask_file = 'Brain_GM_mask_1mm_MNI_kNN_conservative.nii.gz' #None\n",
    "\n",
    "#setup image_size\n",
    "if mask_file is not None:\n",
    "    mask = nib.load(MASK_DIR+mask_file).get_data()\n",
    "    #when applying a mask, initialize zerocropping\n",
    "    img_size = np.array(np.array(zerocrop_img(mask, True, padding=use_padding)).shape)\n",
    "else:\n",
    "    mask = None\n",
    "    img_size = np.array(np.array(nib.load(IMAGE_DIR+os.listdir(IMAGE_DIR)[0]).get_data()).shape)\n",
    "\n",
    "img_size = [int(math.ceil(img_d)) for img_d in img_size*img_scale]\n",
    "print('data shape:', img_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting training of model ---\n",
      "Saved model to /trinity/home/jyu/DeepSurvival/Notebooks/model_BrainAge.json\n",
      "WARNING:tensorflow:From /tmp/ipykernel_29117/2020912042.py:19: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/trinity/home/jyu/yjvenv/lib/python3.7/site-packages/ipykernel_launcher.py:39: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
      "\n",
      "* deprecated from version: 3.0\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training ...\n",
      "Epoch 1/4\n",
      "4/4 [==============================] - 16s 4s/step - loss: 176.3409 - mean_absolute_error: 10.1862 - mean_squared_error: 176.3409 - val_loss: 36.7217 - val_mean_absolute_error: 4.3494 - val_mean_squared_error: 36.7217\n",
      "Epoch 2/4\n",
      "4/4 [==============================] - 14s 3s/step - loss: 184.4881 - mean_absolute_error: 7.0288 - mean_squared_error: 184.4881 - val_loss: 12.6666 - val_mean_absolute_error: 3.1821 - val_mean_squared_error: 12.6666\n",
      "Epoch 3/4\n",
      "4/4 [==============================] - 13s 3s/step - loss: 73.8515 - mean_absolute_error: 7.0577 - mean_squared_error: 73.8515 - val_loss: 36.5774 - val_mean_absolute_error: 5.7933 - val_mean_squared_error: 36.5774\n",
      "Epoch 4/4\n",
      "4/4 [==============================] - 15s 4s/step - loss: 58.2186 - mean_absolute_error: 6.0904 - mean_squared_error: 58.2186 - val_loss: 43.1780 - val_mean_absolute_error: 6.4213 - val_mean_squared_error: 43.1780\n",
      "Succesfully trained the model.\n"
     ]
    }
   ],
   "source": [
    "#train the model and keep track of progress with history\n",
    "print('--- Starting training of model ---')\n",
    "\n",
    "modelversion='BrainAge'\n",
    "history = LossHistory(epochs, modelversion)\n",
    "checkpoint = save_checkpoint(modelversion, model)\n",
    "stoptraining = EarlyStopping(monitor='val_loss', min_delta=0, patience=20, verbose=0, mode='min')\n",
    "\n",
    "patients_per_epoch = min(patients_per_epoch, train_size)\n",
    "steps_per_epoch = int(math.ceil(float(patients_per_epoch)/batch_size))\n",
    "validation_steps = int(math.ceil(float(validation_size)/batch_size))\n",
    "\n",
    "model.fit_generator(data_generator(list(train_set), img_size, batch_size, img_scale, mask, augment=augment_train, mode='train'),\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=data_generator(list(validation_set), img_size, batch_size, img_scale, mask),\n",
    "                    validation_steps=validation_steps,\n",
    "                    max_queue_size=1,\n",
    "                    callbacks=[history, checkpoint,stoptraining])\n",
    "\n",
    "print('Succesfully trained the model.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_29117/2253860868.py:5: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/trinity/home/jyu/yjvenv/lib/python3.7/site-packages/ipykernel_launcher.py:39: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
      "\n",
      "* deprecated from version: 3.0\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 288ms/step\n"
     ]
    }
   ],
   "source": [
    "#prediction on test set\n",
    "model = tf.keras.models.load_model(MODEL_DIR+'model_'+modelversion+'.h5')\n",
    "test_predictions = model.predict_generator(data_generator(list(test_set), img_size, batch_size, img_scale, mask=mask, mode='test',shuffle=False),\n",
    "                                             steps=int(math.ceil(float(len(test_set))/batch_size)),\n",
    "                                             max_queue_size=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'Patient': test_set,\n",
    "        'Real age':  ages,\n",
    "        'Predicted age': test_predictions.tolist()        }\n",
    "\n",
    "result_df = pd.DataFrame(results, columns = ['Patient','Real age','Predicted age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>Real age</th>\n",
       "      <th>Predicted age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ergomri_1604_v_1975212_1069</td>\n",
       "      <td>90.661191</td>\n",
       "      <td>[81.20193481445312]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ergomri_783_mri_9973399_563</td>\n",
       "      <td>68.566735</td>\n",
       "      <td>[70.59112548828125]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ergomri_1391_m_4009993_908</td>\n",
       "      <td>77.867214</td>\n",
       "      <td>[83.75657653808594]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ergo5mri_1420_9319504_7837</td>\n",
       "      <td>76.473648</td>\n",
       "      <td>[79.26387786865234]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Patient   Real age        Predicted age\n",
       "0  ergomri_1604_v_1975212_1069  90.661191  [81.20193481445312]\n",
       "1  ergomri_783_mri_9973399_563  68.566735  [70.59112548828125]\n",
       "2   ergomri_1391_m_4009993_908  77.867214  [83.75657653808594]\n",
       "3   ergo5mri_1420_9319504_7837  76.473648  [79.26387786865234]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
